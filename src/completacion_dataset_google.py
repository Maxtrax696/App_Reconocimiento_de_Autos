import os
from PIL import Image
from icrawler.builtin import GoogleImageCrawler

# Configuraci√≥n
CARPETA_TRAIN = "dataset_dividido/train"
MIN_IMAGENES = 500
MIN_RESOLUCION = (150, 150)
EXTENSIONES_VALIDAS = ('.jpg', '.jpeg', '.png')

def contar_imagenes_validas(carpeta):
    return len([
        f for f in os.listdir(carpeta)
        if f.lower().endswith(EXTENSIONES_VALIDAS)
    ])

def eliminar_imagenes_invalidas(carpeta):
    eliminadas = 0
    for nombre in os.listdir(carpeta):
        ruta = os.path.join(carpeta, nombre)
        if not nombre.lower().endswith(EXTENSIONES_VALIDAS):
            os.remove(ruta)
            eliminadas += 1
            continue
        try:
            with Image.open(ruta) as img:
                if img.size[0] < MIN_RESOLUCION[0] or img.size[1] < MIN_RESOLUCION[1]:
                    os.remove(ruta)
                    eliminadas += 1
        except Exception:
            os.remove(ruta)
            eliminadas += 1
    return eliminadas

def descargar_imagenes(clase, destino, cantidad):
    print(f"üåê Descargando {cantidad} im√°genes para: {clase}")
    crawler = GoogleImageCrawler(
        feeder_threads=1,
        parser_threads=2,
        downloader_threads=4,
        storage={"root_dir": destino}
    )
    # Filtra solo archivos JPEG o PNG y evita SVG, ICO, etc.
    crawler.crawl(
        keyword=clase,
        max_num=cantidad,
        file_idx_offset=len(os.listdir(destino)),
        filters={"type": "photo", "size": "medium"}
    )

def completar_dataset():
    clases = sorted(next(os.walk(CARPETA_TRAIN))[1])
    print(f"üìÇ Clases detectadas: {len(clases)}\n")

    for clase in clases:
        clase_texto = clase.replace("_", " ")
        carpeta_clase = os.path.join(CARPETA_TRAIN, clase)

        eliminadas = eliminar_imagenes_invalidas(carpeta_clase)
        if eliminadas:
            print(f"üßπ {eliminadas} im√°genes inv√°lidas eliminadas de: {clase_texto}")

        actuales = contar_imagenes_validas(carpeta_clase)

        if actuales < MIN_IMAGENES:
            faltan = MIN_IMAGENES - actuales
            print(f"‚ö†Ô∏è  {clase_texto:<30} ‚Üí tiene {actuales} im√°genes ‚Üí faltan {faltan}")
            descargar_imagenes(clase_texto, carpeta_clase, faltan)

            eliminadas = eliminar_imagenes_invalidas(carpeta_clase)
            if eliminadas:
                print(f"üßπ {eliminadas} im√°genes inv√°lidas eliminadas despu√©s de la descarga")
        else:
            print(f"‚úÖ {clase_texto:<30} ‚Üí OK con {actuales} im√°genes")

    # Resumen
    print("\nüìä Resumen final:")
    for clase in clases:
        ruta = os.path.join(CARPETA_TRAIN, clase)
        total = contar_imagenes_validas(ruta)
        print(f"üìÅ {clase:<30} ‚Üí {total} im√°genes v√°lidas")

    print("\n‚úÖ Dataset enriquecido y limpio üéØ")

if __name__ == "__main__":
    completar_dataset()
